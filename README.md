ğŸ¤– WhatsApp AI Assistant (Evolution + Gemini + Redis)

Sistema de atendimento automatizado via WhatsApp, utilizando:

ğŸ“² Evolution API (integraÃ§Ã£o WhatsApp)

ğŸ§  Google Gemini API (IA)

ğŸ—„ Redis (memÃ³ria + debounce inteligente)

ğŸ Flask (Webhook server)

O sistema aguarda 2 minutos apÃ³s a Ãºltima mensagem do cliente antes de responder, permitindo que o usuÃ¡rio envie vÃ¡rias mensagens seguidas e a IA responda de forma consolidada.

ğŸ“Œ Arquitetura
Cliente WhatsApp
        â†“
Evolution API
        â†“
Webhook (Flask)
        â†“
Redis (Buffer + Debounce + HistÃ³rico)
        â†“
Gemini API (IA)
        â†“
Evolution API (sendText)
        â†“
Cliente

ğŸ§  Como Funciona
ğŸ”¹ 1. Recebimento

O webhook recebe eventos messages.upsert.

ğŸ”¹ 2. Buffer Inteligente

Cada mensagem:

Ã‰ armazenada no Redis

Reagenda o tempo de resposta para agora + 120 segundos

ğŸ”¹ 3. Debounce

Se o cliente parar de enviar mensagens por 2 minutos:

Todas as mensagens acumuladas sÃ£o unificadas

A IA gera uma Ãºnica resposta

A resposta Ã© enviada

ğŸ“ Estrutura do Projeto
.
â”œâ”€â”€ webhook.py        # Servidor Flask + OrquestraÃ§Ã£o
â”œâ”€â”€ ai_service.py     # LÃ³gica da IA (Gemini)
â”œâ”€â”€ sender.py         # Envio via Evolution API
â”œâ”€â”€ parser.py         # ExtraÃ§Ã£o de nÃºmero e texto
â”œâ”€â”€ memory.py         # HistÃ³rico Redis
â”œâ”€â”€ buffer.py         # Debounce de 2 minutos
â”œâ”€â”€ .env
â””â”€â”€ README.md

âš™ï¸ VariÃ¡veis de Ambiente
ğŸ”¹ .env
# Evolution
AUTHENTICATION_API_KEY=senha
EVOLUTION_API=http://localhost:8080/message/sendText/secundario

# Webhook
WEBHOOK_ENABLED=true

# Redis
CACHE_REDIS_ENABLED=true
CACHE_REDIS_URI=redis://localhost:6379/6
CACHE_REDIS_PREFIX_KEY=evolution

# Gemini
GEMINI_MODEL=gemini-3-flash-preview


âš  A GEMINI_API_KEY deve estar configurada nas variÃ¡veis do sistema Windows.

ğŸ³ Redis (Docker)

Rodando via container:

docker run -d \
  --name redis \
  -p 6379:6379 \
  redis:7

â–¶ï¸ Executar o Projeto

Instale dependÃªncias:

pip install flask redis python-dotenv google-genai requests


Execute:

python webhook.py


Servidor disponÃ­vel em:

http://localhost:5000/webhook

ğŸ§© Fluxo do Debounce
Exemplo real:

Cliente envia:

Oi
Tudo bem?
Queria saber preÃ§o


Sistema:

Armazena tudo

Espera 2 minutos

Envia uma Ãºnica resposta contextualizada

ğŸ›¡ Controle de Duplicidade

A Evolution pode reenviar eventos mÃºltiplas vezes.
O sistema:

Usa message.key.id

Armazena em Redis com TTL

Ignora mensagens duplicadas

ğŸ” Logs Esperados

Mensagem recebida:

Mensagem recebida de 556992579600: Bom dia


Worker executando:

[worker] respondeu 556992579600: Bom dia! Como posso ajudar?

ğŸ§  IA (Gemini)

Arquivo responsÃ¡vel:

ai_service.py


FunÃ§Ãµes principais:

build_prompt(history, user_text)

generate_reply(history, user_text)

Modelo padrÃ£o:

gemini-3-flash-preview

ğŸ”„ Tratamento de Erros

Redis offline â†’ sistema continua sem debounce

Evento sem texto â†’ ignorado

Payload como lista ou dict â†’ normalizado

Debug mode evita mÃºltiplos workers

ğŸš€ Melhorias Futuras

PersistÃªncia de histÃ³rico em PostgreSQL

Multi-instÃ¢ncia WhatsApp

Painel administrativo

Fila com Celery/Redis

Rate limiting

Logs estruturados

Deploy com Gunicorn + Nginx

Docker Compose completo

ğŸ— Ambiente de ProduÃ§Ã£o

âš  NÃ£o use Flask dev server em produÃ§Ã£o.

Use:

gunicorn webhook:app -w 4 -b 0.0.0.0:5000

ğŸ“Œ ObservaÃ§Ãµes TÃ©cnicas Importantes
Redis URI

Se rodando Flask no Windows e Redis em Docker:

redis://localhost:6379/6


Se tudo estiver em Docker Compose:

redis://redis:6379/6

ğŸ“œ LicenÃ§a

Uso acadÃªmico / experimental.

ğŸ‘¨â€ğŸ’» Autor

Eduardo Henrique
Engenharia de ComputaÃ§Ã£o â€“ UTFPR
Foco em IA, backend e sistemas distribuÃ­dos.